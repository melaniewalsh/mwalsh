{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency–Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download relevant files here](https://melaniewalsh.org/TF-IDF.zip) or run `git pull` from command line in the \"Intro-Cultural-Analytics-Notebooks\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to learn about a text analysis method called **term frequency–inverse document frequency** (tf–idf). This method will help us identify the most unique words in a document from a given corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">term = word <br>\n",
    ">document = text (or chunk of a text) <br>\n",
    ">corpus = collection of texts <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is tf–idf Useful?\n",
    "\n",
    "tf–idf is a very useful and commonly used text analysis method. Why?\n",
    "\n",
    "Let's say we wanted to find out the most interesting or meaningful words in each of the 14 short stories in *Lost in the City*, a short story collection by Edward P. Jones.\n",
    "\n",
    "We could calculate the most *frequent* words in each story. But stop words like \"the\" or \"and\" would be the most frequent words for every single story. We could remove the stop words, but the most frequent words still wouldn't be very interesting. They would be the same or similar for every short story: \"said,\" \"man,\" \"woman,\" \"day.\"\n",
    "\n",
    "Tf–idf can help remedy these problems. That's because tf–idf calculates a uniqueness score for every word based on how many times the word appears in an individual text **as well as** how many times that word appears *in all the other texts in the corpus*. By taking into consideration the entire short story collection, tf–idf helps to identify words that are unique to a given story (i.e., they don't appear very often in the other stories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basic Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `term_frequency * inverse_document_frequency`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than a few ways to calculate tf–idf scores. Understanding the minute details of tf–idf math is not our primary goal, but it's helpful to understand what's happening in broad strokes. Let's walk through one possible tf–idf formula with one example.\n",
    " \n",
    "## Breaking Down the Formula\n",
    "\n",
    "For this version of the formula, `term_frequency` equals the number of times a word appears in one of *Lost in the City*'s short stories..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `term_frequency = number of times a given word appears in story or text`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inverse_document_frequency` equals the total number of short stories  divided by the number of short stories that contain the given word...\n",
    "\n",
    "> `total_number_of_documents / number_of_documents_with_term`\n",
    "\n",
    "...the result of which we're going to take the logarithm of and then add 1\n",
    "\n",
    "> `inverse_document_frequency = log(total_number_of_documents / number_of_documents_with_term) + 1`\n",
    "\n",
    "Do you see how if we flipped the fraction — making it `number_of_documents_with_term /  total_number_of_documents`— that would just be \"document frequency\"? By inverting this fraction, however, we get \"inverse document frequency.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Formula in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"said\" vs \"pigeons\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this formula, we're going to calculate and compare the tf–idf scores for the word \"said\" and the word \"pigeons\" in \"The Girl Who Raised Pigeons,\" the first short story in *Lost in the City*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the log() function for our calculation, so we're going to import it from the `math` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"said\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_documents = 14 #total number of short stories in *Lost in the City*\n",
    "number_of_documents_with_term = 13 #number of short stories the contain the word \"said\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = 47 #number of times \"said\" appears in \"The Girl Who Raised Pigeons\"\n",
    "inverse_document_frequency = log(total_number_of_documents / number_of_documents_with_term) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency * inverse_document_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"pigeons\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_documents = 14 #total number of short stories in *Lost in the City*\n",
    "number_of_documents_with_term = 2 #number of short stories the contain the word \"pigeons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = 30 #number of times \"pigeons\" appears in \"The Girl Who Raised Pigeons\"\n",
    "inverse_document_frequency = log(total_number_of_documents / number_of_documents_with_term) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency * inverse_document_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf–idf Scores**\n",
    "\n",
    "\"said\" = 50.48<br>\n",
    "\"pigeons\" = 88.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the word \"said\" appears 47 times in \"The Girl Who Raised Pigeons\" and the word \"pigeons\" only appears 30 times, \"pigeons\" has a higher tf–idf score than \"said\" because it's a rarer word. The word \"pigeons\" appears in 2 of 14 stories, while \"said\" appears in 13 of 14 stories, almost all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf–idf with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could continue calculating tf–idf scores in this manner — by doing all the math with Python — but conveniently there's a Python library that can calculate tf–idf scores in just a few lines of code.\n",
    "\n",
    "This library is called [scikit-learn](https://scikit-learn.org/stable/index.html), imported as `sklearn`. It's a popular Python library for machine learning approaches such as clustering, classification, and regression, among others. Though we're not doing any machine learning in this lesson, we're nevertheless going to use scikit-learn's `TfidfVectorizer` and `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/melaniewalsh/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/melaniewalsh/anaconda3/lib/python3.7/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/melaniewalsh/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/melaniewalsh/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to import `pandas` and change two of its default display settings. We're going to increase the maximum number of rows that pandas will display, and we're going to format numbers in a special way. If it's a decimal number, format to three decimal places; if it's a whole number, round to the whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"max_rows\", 200)\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "pd.options.display.float_format = lambda value : '{:.0f}'.format(value) if round(value,0) == value else '{:,.3f}'.format(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to import two libraries that will help us work with files and the file system: [`pathlib`](https://docs.python.org/3/library/pathlib.html#basic-use) and [`glob`](https://docs.python.org/3/library/glob.html). These libraries will help us read in all the short story text files from *Lost in the City*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Directory Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we're setting the directory filepath that contains all the short story text files that we want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"../texts/literature/Lost-in-the-City_Stories/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're going to use `glob` and `Path` to make a list of all the short story filepaths in that directory and a list of all the short story titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob(f\"{directory_path}/*.txt\")\n",
    "text_titles = [Path(text).stem for text in text_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display them to make sure they're correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../texts/literature/Lost-in-the-City_Stories/11-Gospel.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/13-A-Dark-Night.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/01-The-Girl-Who-Raised-Pigeons.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/12-A-New-Man.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/02-The-First-Day.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/07-The-Sunday-Following-Mother’S-Day.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/03-The-Night-Rhonda-Ferguson-Was-Killed.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/05-The-Store.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/08-Lost-In-The-City.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/14-Marie.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/09-His-Mother’S-House.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/10-A-Butterfly-On-F-Street.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/06-An-Orange-Line-Train-To-Ballston.txt',\n",
       "  '../texts/literature/Lost-in-the-City_Stories/04-Young-Lions.txt'],\n",
       " ['11-Gospel',\n",
       "  '13-A-Dark-Night',\n",
       "  '01-The-Girl-Who-Raised-Pigeons',\n",
       "  '12-A-New-Man',\n",
       "  '02-The-First-Day',\n",
       "  '07-The-Sunday-Following-Mother’S-Day',\n",
       "  '03-The-Night-Rhonda-Ferguson-Was-Killed',\n",
       "  '05-The-Store',\n",
       "  '08-Lost-In-The-City',\n",
       "  '14-Marie',\n",
       "  '09-His-Mother’S-House',\n",
       "  '10-A-Butterfly-On-F-Street',\n",
       "  '06-An-Orange-Line-Train-To-Ballston',\n",
       "  '04-Young-Lions'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files, text_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Word Frequency (Optional Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an optional step, but for the sake of comparison, we're first going to calculate the raw frequency for every word in every story with scikit-learn's [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Later, when we calculate our tf–idf scores, we can compare these two methods and see how tf–idf helps us find more unique words.\n",
    "\n",
    "(Machine learning approaches require that you transform words into a \"vector,\" aka a series of numbers. This is what `CountVectorizer` does. But it's also just a convenient way to tokenize and count words.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize CountVectorizer with desired parameters\n",
    "count_vectorizer= CountVectorizer(input='filename', stop_words='english')\n",
    "\n",
    "#Plug in \"text_files,\" which contains all our short stories, to the initialized count_vectorizer\n",
    "word_count_vector = count_vectorizer.fit_transform(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a DataFrame out of the word count vector and sort by title\n",
    "word_count_df = pd.DataFrame(word_count_vector.toarray(), index=text_titles, columns=count_vectorizer.get_feature_names())\n",
    "word_count_df = word_count_df.sort_index()\n",
    "\n",
    "#Add column for number of times each word appears in all the documents\n",
    "word_count_df.loc['Document Frequency'] = (word_count_df > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe `word_count_df` displays all the words that appear in *Lost in the City*, how many times each word appears in each story, and how many times each word appears at least once across all the stories (the very last row of numbers titled \"Document Frequency\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample of 10 words. You can run the cell again to look at a different sample of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df.sample(10, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on some specific words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df[['pigeons', 'school', 'said', 'gospelteers', 'church', 'thunder','girl', 'street', 'father', 'dreaming', 'car']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the top 10 most frequent words in every story, we're going to make and run the following function: `get_top_n_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_counts(dataframe, top_n=10):\n",
    "    pretty_df = dataframe.stack().groupby(level=0).nlargest(top_n).reset_index()\n",
    "    pretty_df = pretty_df.rename(columns={0:'count', 'level_1': 'story', 'level_2': 'word'})\n",
    "    pretty_df = pretty_df.drop(columns='level_0')\n",
    "    pretty_df['word_freq_rank'] = pretty_df.groupby('story')['count'].rank(method='min', ascending=False)\n",
    "    return pretty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will rearrange the dataframe, `.groupby()` short story, and filter for the top 10 most frequent words in every story. Finally, it will produce a dataframe with a new column `word_freq_rank`, which contains a 1-10 ranking of the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_count_df = word_count_df.drop('Document Frequency', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "top_word_freq = get_top_n_counts(word_count_df)\n",
    "top_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate tf–idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate tf–idf scores for every word, we're going to follow a very similar pattern with scikit-learn's [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "When you initialize TfidfVectorizer, you can choose to set it with different parameters. These parameters will change the way you calculate tf–idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Smoothing or Normalization (Not Recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we calculated the tf–idf score for the word \"pigeons\" above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.3773044716594"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_documents = 14 \n",
    "number_of_documents_with_term = 2\n",
    "term_frequency = 30\n",
    "inverse_document_frequency = log(total_number_of_documents / number_of_documents_with_term) + 1\n",
    "\n",
    "term_frequency * inverse_document_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this exact formula by running `TfidfVectorizer` and turning off smoothing (`smoth_idf=False`) and normalization (`norm=None`). This is **not** the best or recommended way to calculate tf–idf scores. But it's useful to see the basic math that we discussed earlier in action with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize TfidfVectorizer with desired parameters (turn off smoothing and normalization)\n",
    "tfidf_vectorizer = TfidfVectorizer(input='filename', stop_words='english', smooth_idf = False, norm=None)\n",
    "\n",
    "#Plug in \"text_files\" which contains all our short stories\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a DataFrame out of the tf–idf vector and sort by title\n",
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=text_titles, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df = tfidf_df.sort_index()\n",
    "\n",
    "#Add column for number of times word appears in all documents\n",
    "tfidf_df.loc['Document Frequency'] = (tfidf_df > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_slice = tfidf_df[['pigeons', 'school', 'said', 'church', 'gospelteers', 'thunder','girl', 'street', 'father', 'dreaming', 'car']]\n",
    "tfidf_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Smoothing and Normalization (Defaults/Recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended way to run `TfidfVectorizer`, however, is with smoothing (`smooth_idf = True`) and normalization (`norm='l2'`) turned on. These parameters will better account for differences in story length, and, overall, they'll produce more meaningful tf–idf scores. \n",
    "\n",
    "Smoothing and L2 normalization are actually the default settings for `TfidfVectorizer`. To turn them on, you don't need to include any extra code at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize TfidfVectorizer with desired parameters (default smoothing and normalization)\n",
    "tfidf_vectorizer = TfidfVectorizer(input='filename', stop_words='english')\n",
    "\n",
    "#Plug in \"text_files\" which contains all our short stories\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a DataFrame out of the tf–idf vector and sort by title\n",
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=text_titles, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df = tfidf_df.sort_index()\n",
    "\n",
    "#Add column for number of times word appears in all documents\n",
    "tfidf_df.loc['Document Frequency'] = (tfidf_df > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_slice = tfidf_df[['pigeons', 'school', 'said', 'church', 'gospelteers', 'thunder','girl', 'street', 'father', 'dreaming', 'car']]\n",
    "tfidf_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out the top 10 words with the highest tf–idf for every story, we're going to make and run the following function: `get_top_tfidf_scores()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tfidf_scores(series, top_n=10):\n",
    "    pretty_df = series.stack().groupby(level=0).nlargest(top_n).reset_index()\n",
    "    pretty_df = pretty_df.rename(columns={0:'tfidf_score', 'level_1': 'story', 'level_2': 'word'})\n",
    "    pretty_df = pretty_df.drop(columns='level_0')\n",
    "    pretty_df['tfidf_rank'] = pretty_df.groupby('story')['tfidf_score'].rank(method='first', ascending=False)\n",
    "    return pretty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, this function will rearrange the dataframe, `.groupby()` short story, and filter for the top 10 highest tf–idf scores in every story. Finally, it will produce a dataframe with a new column `tfidf_rank`, which contains a 1-10 ranking of the highest tf–idf scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df.drop('Document Frequency', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_tfidf = get_top_tfidf_scores(tfidf_df)\n",
    "top_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"tfidf_Lost-in-The-City.csv\"\n",
    "top_tfidf.to_csv(filename, encoding='UTF-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Word Frequency and tf–idf Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the raw word frequencies and tf-idf scores for all the stories in the *Lost in the City*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to merge the top raw word frequency ranks into our top tf–idf dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare = top_tfidf.merge(top_word_freq[['word_freq_rank', 'word', 'story']] , on=['story', 'word'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're going to add a column that calculates the change in rank—that is, how the significance of a word changes when we calculate tf-idf vs raw word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare['changed_rank'] = tfidf_compare['word_freq_rank'] - tfidf_compare['tfidf_rank']\n",
    "tfidf_compare = tfidf_compare.fillna(\"*new top word*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to make some functions that will alter the style of our Pandas dataframe—such that the words that move up in tf-idf rank will be emphasized in green with a `+` sign and words that move down in tf-idf rank will be emphasized in red with a `-` sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positive(value):\n",
    "    if value != '*new top word*':\n",
    "        if float(value) > 0:\n",
    "            value = f'+{round(value)}'\n",
    "    return value\n",
    "\n",
    "def make_bold(value):\n",
    "    return 'font-weight: bold'\n",
    "\n",
    "def color_df(value):\n",
    "    if value == '*new top word*':\n",
    "        color = 'green'    \n",
    "    else:\n",
    "        value = str(value).replace('+', '')\n",
    "        value = float(value)\n",
    "        \n",
    "        if value < 0:\n",
    "            color = 'red'\n",
    "        elif value > 0:\n",
    "            color = 'green'\n",
    "        else:\n",
    "             color = 'black'        \n",
    "    df_style = f'color: {color}; font-weight: bold'\n",
    "    return df_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's display the dataframe and explore which words have become more significant and which words have become less so>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare['changed_rank'] = tfidf_compare['changed_rank'].apply(make_positive)\n",
    "tfidf_compare_styled = tfidf_compare.style.applymap(color_df, subset=['changed_rank']).applymap(make_bold, subset=['tfidf_rank'])\n",
    "tfidf_compare_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"said,\" which is one of the most frequent words throughout the collection, gets knocked down in tf-idf importance precisely because it occurs in almost every story.\n",
    "\n",
    "*Note: To style your dataframe with color and bolding (as above), add `.style.applymap(color_df, subset=['changed_rank'])` to the end of the code below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare[tfidf_compare['word'] == 'said']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word like \"pigeons,\" on the other hand, becomes more significant because it is rarer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare[tfidf_compare['word'] == 'pigeons']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that were not frequent enough to make the top 10 for raw word frequency — such as \"dreaming,\" \"gospelteers,\" or \"dreadlocks — now suddenly show up in the top 10 for tf-idf scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare[tfidf_compare['word'] == 'dreaming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare[tfidf_compare['word'] == 'gospelteers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_compare[tfidf_compare['word'] == 'dreadlocks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few minutes to explore the dataframe below and then answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** What is the difference between a tf-idf score and raw word frequency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#** Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Based on the dataframe above, what is one potential problem or limitation that you notice with tf-idf scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#** Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** What's another collection of texts that you think might be interesting to analyze with tf-idf scores?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#** Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
